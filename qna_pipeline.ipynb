{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-06-13T16:06:18.752094Z","iopub.status.busy":"2023-06-13T16:06:18.751598Z","iopub.status.idle":"2023-06-13T16:07:03.334262Z","shell.execute_reply":"2023-06-13T16:07:03.332000Z","shell.execute_reply.started":"2023-06-13T16:06:18.752059Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install -q accelerate==0.20.3\n","!pip install -q transformers==4.30.0\n","!pip install -q sentence-transformers==2.2.2"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-06-13T16:07:03.344875Z","iopub.status.busy":"2023-06-13T16:07:03.343722Z","iopub.status.idle":"2023-06-13T16:07:18.370197Z","shell.execute_reply":"2023-06-13T16:07:18.368677Z","shell.execute_reply.started":"2023-06-13T16:07:03.344805Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]}],"source":["# standard\n","import os\n","import numpy as np\n","import pandas as pd\n","import pickle\n","\n","# DL\n","import torch\n","import transformers\n","from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n","import sentence_transformers\n","\n","# ML\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from nltk.tokenize import sent_tokenize"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-06-13T16:07:18.373555Z","iopub.status.busy":"2023-06-13T16:07:18.372913Z","iopub.status.idle":"2023-06-13T16:07:18.515377Z","shell.execute_reply":"2023-06-13T16:07:18.513631Z","shell.execute_reply.started":"2023-06-13T16:07:18.373503Z"},"trusted":true},"outputs":[],"source":["# Loading Data\n","\n","file_name = '/kaggle/input/qna-data2/section_wise_data.txt'\n","with open(file_name, 'r') as f:\n","    data = f.read()\n","    pass\n","\n","# Loading Data that is saved in the webpages \n","# Structured this way for downstream tasks\n","level1 = data.split(\"<<<<>>>>\")[:-1]\n","tree_data = []\n","for paper in level1:\n","    parts = paper.split(\"<<<>>>\")\n","    tree_data.append({\"meta\": parts[0], \"content\":parts[1]})\n","    pass\n","\n","for paper in tree_data:\n","    parts = paper[\"content\"].split(\"<<>>\")\n","    paper[\"content\"] = []\n","    for part in parts:\n","        innersplit = part.split(\"<>\")\n","        paper[\"content\"].append({\"heading\": innersplit[0], \"body\":innersplit[1]})\n","        pass\n","    pass\n","\n","corpus = [content[\"body\"] for paper in tree_data for content in paper[\"content\"]]\n","corpus = ' '.join(corpus)\n","corpus = sent_tokenize(corpus)\n","corpus = np.array(corpus)\n","\n","# Corpus is an np array of sentences. Each sentence corresponds to one document for us"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-13T16:07:18.519285Z","iopub.status.busy":"2023-06-13T16:07:18.518823Z","iopub.status.idle":"2023-06-13T16:07:18.542602Z","shell.execute_reply":"2023-06-13T16:07:18.541137Z","shell.execute_reply.started":"2023-06-13T16:07:18.519251Z"},"trusted":true},"outputs":[],"source":["class QnAModel():\n","    def __init__(self, model_corpus, retreiver_model = None, ST_retreiver: str = None, gen_model = None):\n","        self.corpus = model_corpus\n","        \n","        # Retreiver model\n","        if retreiver_model == None:\n","            retreiver_model = \"deepset/roberta-base-squad2\"\n","        self.retreiver_model = pipeline('question-answering', model=retreiver_model, tokenizer = retreiver_model)\n","        \n","        \n","        # Sentence tarnsformer model (unused)\n","        self.ST_retreiver = sentence_transformers.SentenceTransformer(ST_retreiver)\n","        \n","        #Generator Model\n","        if gen_model == None:\n","            gen_model = pickle.load(open('/kaggle/input/models/flan-t5-large-finetuned-finetuning_final_data-10_epochs.h5', 'rb'))\n","            self.gen_model = transformers.pipeline(\"text2text-generation\", model = gen_model, tokenizer = 'google/flan-t5-large')\n","        else:\n","            self.gen_model = transformers.pipeline(\"text2text-generation\", model = gen_model, tokenizer = gen_model)\n","        \n","        pass\n","    \n","    def tf_idf_retreival(self, query, k):\n","        # Retrieving relvant documents using tf-idf\n","        vectorizer = TfidfVectorizer()\n","\n","        query_emb = vectorizer.fit_transform(self.corpus)\n","        doc_emb = vectorizer.transform([query])\n","        Z = cosine_similarity(doc_emb, query_emb)[0]\n","        top_ind = np.argsort(Z)[::-1][:k]\n","        top_docs = self.corpus[top_ind]\n","        return top_docs\n","        \n","    def DL_retreiver(self, query, top_documents, n):\n","        # Retrieving top documents using an end to end question answering model\n","        results = []\n","        for doc in top_documents:\n","            QA_input = QA_input = {\n","                'question': query,\n","                'context': doc\n","            }\n","            res = self.retreiver_model(QA_input)\n","            results.append((doc, res['score']))\n","\n","        # get top n scores\n","        final = sorted(results, key=lambda x: x[1])[::-1][:n]\n","        return final\n","        \n","    def SentenceTransform_retreiver(self, query, top_documents, n):\n","        # retreiving top documents using a sentence transformer using vector embedding similarities \n","        if self.ST_retreiver == None:\n","            raise Exception(\"Sentence Transformer not provided.\")\n","        \n","        query_emb = self.ST_retreiver.encode([query])\n","        doc_emb = self.ST_retreiver.encode(top_documents)\n","        scores  = cosine_similarity(query_emb, doc_emb)[0]\n","        doc_score_pairs = list(zip(top_documents, scores))\n","        doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)[:n]\n","        return doc_score_pairs\n","    \n","    def generate_result(self, query, top_documents, max_length):\n","        # Generating results using a text to text generator model\n","        \n","        # Our top douments are the context for the model\n","        context = ' '.join(top_documents)\n","        \n","        # We prompt the task to the model\n","        prompt = f'Answer this question: {query} \\n Given this is true: {context}'\n","        return self.gen_model(prompt, max_length=max_length)\n","    \n","    def answer_question(self, query, k = 50, n = 5, max_length = 75, use_sent_transformer = False):\n","        # tf idf\n","        top_documents = self.tf_idf_retreival(query, k)\n","        # retreive\n","        if use_sent_transformer:\n","            top_documents = self.SentenceTransform_retreiver(query, top_documents, n)\n","        else:\n","            top_documents = self.DL_retreiver(query, top_documents, n)\n","            #print(top_documents)\n","        \n","        \n","        # generate\n","        top_documents = [pair[0] for pair in top_documents]          \n","        \n","        output = self.generate_result(query, top_documents, max_length)\n","        \n","        return output"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-13T16:07:18.545703Z","iopub.status.busy":"2023-06-13T16:07:18.545221Z","iopub.status.idle":"2023-06-13T16:07:38.959447Z","shell.execute_reply":"2023-06-13T16:07:38.958009Z","shell.execute_reply.started":"2023-06-13T16:07:18.545633Z"},"trusted":true},"outputs":[],"source":["# initialise our model\n","My_Model = QnAModel(corpus)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-13T16:08:46.780640Z","iopub.status.busy":"2023-06-13T16:08:46.779722Z","iopub.status.idle":"2023-06-13T16:09:51.552384Z","shell.execute_reply":"2023-06-13T16:09:51.551170Z","shell.execute_reply.started":"2023-06-13T16:08:46.780585Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["When did the GARDASIL 9 recommendations change?\n","[{'generated_text': 'February 2015'}]\n","\n","What were the past 3 recommendation changes for GARDASIL 9?\n","[{'generated_text': 'the recommendation was designated as a Category A recommendation (recommendation for all persons in an age- or risk-factorâ€“based group) (6). Antibody titers were higher after the third dose than after the first dose. The main analyses were restricted to participants who received all 3 doses, had no evidence of current or past infection'}]\n","\n","Is GARDASIL 9 recommended for Adults?\n","[{'generated_text': 'yes'}]\n","\n","Does the ACIP recommend one dose GARDASIL 9?\n","[{'generated_text': 'no'}]\n","\n"]}],"source":["questions = [\n","    \"When did the GARDASIL 9 recommendations change?\" ,\n","    \"What were the past 3 recommendation changes for GARDASIL 9?\",\n","    \"Is GARDASIL 9 recommended for Adults?\",\n","    \"Does the ACIP recommend one dose GARDASIL 9?\"\n","]\n","\n","for question in questions:\n","    print(question)\n","    print(My_Model.answer_question(query=question, k=50, n=10))\n","    print()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
