{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q accelerate==0.20.3\n!pip install -q transformers==4.30.0\n!pip install -q sentence-transformers==2.2.2","metadata":{"execution":{"iopub.status.busy":"2023-06-13T16:06:18.751598Z","iopub.execute_input":"2023-06-13T16:06:18.752094Z","iopub.status.idle":"2023-06-13T16:07:03.334262Z","shell.execute_reply.started":"2023-06-13T16:06:18.752059Z","shell.execute_reply":"2023-06-13T16:07:03.332000Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# standard\nimport os\nimport numpy as np\nimport pandas as pd\nimport pickle\n\n# DL\nimport torch\nimport transformers\nfrom transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\nimport sentence_transformers\n\n# ML\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom nltk.tokenize import sent_tokenize","metadata":{"execution":{"iopub.status.busy":"2023-06-13T16:07:03.343722Z","iopub.execute_input":"2023-06-13T16:07:03.344875Z","iopub.status.idle":"2023-06-13T16:07:18.370197Z","shell.execute_reply.started":"2023-06-13T16:07:03.344805Z","shell.execute_reply":"2023-06-13T16:07:18.368677Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Loading Data\n\nfile_name = '/kaggle/input/qna-data2/section_wise_data.txt'\nwith open(file_name, 'r') as f:\n    data = f.read()\n    pass\n\n# Loading Data that is saved in the webpages \n# Structured this way for downstream tasks\nlevel1 = data.split(\"<<<<>>>>\")[:-1]\ntree_data = []\nfor paper in level1:\n    parts = paper.split(\"<<<>>>\")\n    tree_data.append({\"meta\": parts[0], \"content\":parts[1]})\n    pass\n\nfor paper in tree_data:\n    parts = paper[\"content\"].split(\"<<>>\")\n    paper[\"content\"] = []\n    for part in parts:\n        innersplit = part.split(\"<>\")\n        paper[\"content\"].append({\"heading\": innersplit[0], \"body\":innersplit[1]})\n        pass\n    pass\n\ncorpus = [content[\"body\"] for paper in tree_data for content in paper[\"content\"]]\ncorpus = ' '.join(corpus)\ncorpus = sent_tokenize(corpus)\ncorpus = np.array(corpus)\n\n# Corpus is an np array of sentences. Each sentence corresponds to one document for us","metadata":{"execution":{"iopub.status.busy":"2023-06-13T16:07:18.372913Z","iopub.execute_input":"2023-06-13T16:07:18.373555Z","iopub.status.idle":"2023-06-13T16:07:18.515377Z","shell.execute_reply.started":"2023-06-13T16:07:18.373503Z","shell.execute_reply":"2023-06-13T16:07:18.513631Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class QnAModel():\n    def __init__(self, model_corpus, retreiver_model = None, ST_retreiver: str = None, gen_model = None):\n        self.corpus = model_corpus\n        \n        # Retreiver model\n        if retreiver_model == None:\n            retreiver_model = \"deepset/roberta-base-squad2\"\n        self.retreiver_model = pipeline('question-answering', model=retreiver_model, tokenizer = retreiver_model)\n        \n        \n        # Sentence tarnsformer model (unused)\n        self.ST_retreiver = sentence_transformers.SentenceTransformer(ST_retreiver)\n        \n        #Generator Model\n        if gen_model == None:\n            gen_model = pickle.load(open('/kaggle/input/models/flan-t5-large-finetuned-finetuning_final_data-10_epochs.h5', 'rb'))\n            self.gen_model = transformers.pipeline(\"text2text-generation\", model = gen_model, tokenizer = 'google/flan-t5-large')\n        else:\n            self.gen_model = transformers.pipeline(\"text2text-generation\", model = gen_model, tokenizer = gen_model)\n        \n        pass\n    \n    def tf_idf_retreival(self, query, k):\n        # Retrieving relvant documents using tf-idf\n        vectorizer = TfidfVectorizer()\n\n        query_emb = vectorizer.fit_transform(self.corpus)\n        doc_emb = vectorizer.transform([query])\n        Z = cosine_similarity(doc_emb, query_emb)[0]\n        top_ind = np.argsort(Z)[::-1][:k]\n        top_docs = self.corpus[top_ind]\n        return top_docs\n        \n    def DL_retreiver(self, query, top_documents, n):\n        # Retrieving top documents using an end to end question answering model\n        results = []\n        for doc in top_documents:\n            QA_input = QA_input = {\n                'question': query,\n                'context': doc\n            }\n            res = self.retreiver_model(QA_input)\n            results.append((doc, res['score']))\n\n        # get top n scores\n        final = sorted(results, key=lambda x: x[1])[::-1][:n]\n        return final\n        \n    def SentenceTransform_retreiver(self, query, top_documents, n):\n        # retreiving top documents using a sentence transformer using vector embedding similarities \n        if self.ST_retreiver == None:\n            raise Exception(\"Sentence Transformer not provided.\")\n        \n        query_emb = self.ST_retreiver.encode([question])\n        doc_emb = self.ST_retreiver.encode(top_documents)\n        scores  = cosine_similarity(query_emb, doc_emb)[0]\n        doc_score_pairs = list(zip(top_docs, scores))\n        doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)[:n]\n        return doc_score_pairs\n    \n    def generate_result(self, query, top_documents, max_length):\n        # Generating results using a text to text generator model\n        \n        # Our top douments are the context for the model\n        context = ' '.join(top_documents)\n        \n        # We prompt the task to the model\n        prompt = f'Answer this question: {query} \\n Given this is true: {context}'\n        return self.gen_model(prompt, max_length=max_length)\n    \n    def answer_question(self, query, k = 50, n = 5, max_length = 75, use_sent_transformer = False):\n        # tf idf\n        top_documents = self.tf_idf_retreival(query, k)\n        # retreive\n        if use_sent_transformer:\n            top_documents = self.SentenceTransform_retreiver(query, top_documents, n)\n        else:\n            top_documents = self.DL_retreiver(query, top_documents, n)\n            #print(top_documents)\n        \n        \n        # generate\n        top_documents = [pair[0] for pair in top_documents]          \n        \n        output = self.generate_result(query, top_documents, max_length)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2023-06-13T16:07:18.518823Z","iopub.execute_input":"2023-06-13T16:07:18.519285Z","iopub.status.idle":"2023-06-13T16:07:18.542602Z","shell.execute_reply.started":"2023-06-13T16:07:18.519251Z","shell.execute_reply":"2023-06-13T16:07:18.541137Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# initialise our model\nMy_Model = QnAModel(corpus)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T16:07:18.545221Z","iopub.execute_input":"2023-06-13T16:07:18.545703Z","iopub.status.idle":"2023-06-13T16:07:38.959447Z","shell.execute_reply.started":"2023-06-13T16:07:18.545633Z","shell.execute_reply":"2023-06-13T16:07:38.958009Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"questions = [\n    \"When did the GARDASIL 9 recommendations change?\" ,\n    \"What were the past 3 recommendation changes for GARDASIL 9?\",\n    \"Is GARDASIL 9 recommended for Adults?\",\n    \"Does the ACIP recommend one dose GARDASIL 9?\"\n]\n\nfor question in questions:\n    print(question)\n    print(My_Model.answer_question(query=question, k=50, n=10))\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-06-13T16:08:46.779722Z","iopub.execute_input":"2023-06-13T16:08:46.780640Z","iopub.status.idle":"2023-06-13T16:09:51.552384Z","shell.execute_reply.started":"2023-06-13T16:08:46.780585Z","shell.execute_reply":"2023-06-13T16:09:51.551170Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"When did the GARDASIL 9 recommendations change?\n[{'generated_text': 'February 2015'}]\n\nWhat were the past 3 recommendation changes for GARDASIL 9?\n[{'generated_text': 'the recommendation was designated as a Category A recommendation (recommendation for all persons in an age- or risk-factor–based group) (6). Antibody titers were higher after the third dose than after the first dose. The main analyses were restricted to participants who received all 3 doses, had no evidence of current or past infection'}]\n\nIs GARDASIL 9 recommended for Adults?\n[{'generated_text': 'yes'}]\n\nDoes the ACIP recommend one dose GARDASIL 9?\n[{'generated_text': 'no'}]\n\n","output_type":"stream"}]}]}